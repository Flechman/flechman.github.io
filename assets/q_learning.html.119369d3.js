const e={key:"v-2214a351",path:"/notes/q_learning/q_learning.html",title:"Reinforcement Learning: Q-Learning & Deep Q-Learning",lang:"en-US",frontmatter:{},excerpt:"",headers:[{level:2,title:"Introduction",slug:"introduction",children:[]},{level:2,title:"Framework",slug:"framework",children:[]},{level:2,title:"Defining The Goal",slug:"defining-the-goal",children:[{level:3,title:"The V-Function",slug:"the-v-function",children:[]}]},{level:2,title:"The Q-Function",slug:"the-q-function",children:[{level:3,title:"Definition",slug:"definition",children:[]},{level:3,title:"Link To Our Goal",slug:"link-to-our-goal",children:[]},{level:3,title:"Policy Ordering",slug:"policy-ordering",children:[]}]},{level:2,title:"Finding The Optimal V-Function Is Equivalent To Finding The Optimal Q-Function",slug:"finding-the-optimal-v-function-is-equivalent-to-finding-the-optimal-q-function",children:[{level:3,title:"Policy Improvement Lemma",slug:"policy-improvement-lemma",children:[]},{level:3,title:"Equivalence Theorem",slug:"equivalence-theorem",children:[]}]},{level:2,title:"Q-Learning",slug:"q-learning",children:[{level:3,title:"Constraints For Convergence",slug:"constraints-for-convergence",children:[]},{level:3,title:"Exploration-Exploitation tradeoff",slug:"exploration-exploitation-tradeoff",children:[]},{level:3,title:"Implementation Pseudocode",slug:"implementation-pseudocode",children:[]}]},{level:2,title:"Deep-Q-Learning",slug:"deep-q-learning",children:[{level:3,title:"Implementation Pseudocode",slug:"implementation-pseudocode-1",children:[]}]},{level:2,title:"References",slug:"references",children:[]},{level:2,title:"Appendix",slug:"appendix",children:[]}],git:{updatedTime:1758489527e3},filePathRelative:"notes/q_learning/q_learning.md"};export{e as data};
